{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have seen, [BenchmarkTools.jl](https://github.com/JuliaCI/BenchmarkTools.jl) provides tools to micro-benchmark specific functions. However, sometimes we want to zoom out and identify bottlenecks in a larger code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profiling: Serial / Multithreading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Built-in statistical profiler (`Profile`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example code:\n",
    "\n",
    "```julia\n",
    "function matmul(n, k=n)\n",
    "    A = rand(n, k)\n",
    "    B = rand(k, n)\n",
    "    C = zeros(n, n)\n",
    "    for n in axes(C, 2)\n",
    "        for m in axes(C, 1)\n",
    "            Cmn = zero(eltype(C))\n",
    "            for k in axes(A, 2)\n",
    "                tmp = A[m, k] * B[k, n]\n",
    "                Cmn += tmp\n",
    "            end\n",
    "            C[m, n] = Cmn\n",
    "        end\n",
    "    end\n",
    "    return C\n",
    "end\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example output:\n",
    "\n",
    "```\n",
    "Count  Overhead File                    Line Function\n",
    " =====  ======== ====                    ==== ========\n",
    "    52         0 In[1]                      9 matmul(n::Int64, k::Int64)\n",
    "     1         0 In[1]                     10 matmul(n::Int64, k::Int64)\n",
    "     4         3 In[1]                     11 matmul(n::Int64, k::Int64)\n",
    "    57         0 @Base/boot.jl            385 eval\n",
    "    57         0 @Base/essentials.jl      892 #invokelatest#2\n",
    "    50        50 @Base/essentials.jl       14 getindex\n",
    "    57         0 @Base/essentials.jl      889 invokelatest\n",
    "     2         2 @Base/float.jl           411 *\n",
    "     1         1 @Base/float.jl           409 +\n",
    "    57         0 @Base/loading.jl        2076 include_string(mapexpr::typeof(RE…\n",
    "    57         0 …ulia/src/eventloop.jl    38 (::IJulia.var\"#15#18\")()\n",
    "    57         0 …ulia/src/eventloop.jl     8 eventloop(socket::ZMQ.Socket)\n",
    "    57         0 …rc/execute_request.jl    67 execute_request(socket::ZMQ.Socke…\n",
    "    57         0 …rc/SoftGlobalScope.jl    65 softscope_include_string(m::Modul…\n",
    "Total snapshots: 57. Utilization: 100% across all threads and tasks. Use the `groupby` kwarg to break down by thread and/or task.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization\n",
    "\n",
    "A much nicer way to analyze the profiling results is to visualize them as a flame graph. One can choose from a number of visualization tools, including [PProf.jl](https://github.com/JuliaPerf/PProf.jl) and [ProfileView.jl](https://github.com/timholy/ProfileView.jl).\n",
    "\n",
    "I recommend to use the [Julia extension for Visual Studio Code (VS Code)](https://www.julia-vscode.org/) which has built-in [profiling visualization capabilities](https://www.julia-vscode.org/docs/stable/userguide/profiler/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.julia-vscode.org/docs/stable/images/profiler1.png\" width=800px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instrumented Profiling with [TimerOutputs.jl](https://github.com/KristofferC/TimerOutputs.jl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Example code:\n",
    "\n",
    "```julia\n",
    "using TimerOutputs\n",
    "\n",
    "function matmul_instrumented(n, k=n)\n",
    "    @timeit \"initialize matrices\" begin\n",
    "        @timeit \"init A\" A = rand(n, k)\n",
    "        @timeit \"init B\" B = rand(k, n)\n",
    "        @timeit \"init C\" C = zeros(n, n)\n",
    "    end\n",
    "    # simple matmul implementation\n",
    "    @timeit \"matmul\" for n in axes(C, 2)\n",
    "        for m in axes(C, 1)\n",
    "            Cmn = zero(eltype(C))\n",
    "            for k in axes(A, 2)\n",
    "                @timeit \"mul\" tmp = A[m, k] * B[k, n]\n",
    "                @timeit \"add\" Cmn += tmp\n",
    "            end\n",
    "            C[m, n] = Cmn\n",
    "        end\n",
    "    end\n",
    "    return C\n",
    "end\n",
    "```\n",
    "\n",
    "Example output:\n",
    "\n",
    "```\n",
    "────────────────────────────────────────────────────────────────────────────────\n",
    "                                        Time                    Allocations      \n",
    "                               ───────────────────────   ────────────────────────\n",
    "       Tot / % measured:           43.0ms /  98.9%            104KiB /  94.5%    \n",
    "\n",
    " Section               ncalls     time    %tot     avg     alloc    %tot      avg\n",
    " ────────────────────────────────────────────────────────────────────────────────\n",
    " matmul                     1   42.5ms  100.0%  42.5ms   1.47KiB    1.5%  1.47KiB\n",
    "   mul                   100k   7.02ms   16.5%  70.2ns     0.00B    0.0%    0.00B\n",
    "   add                   100k   6.52ms   15.3%  65.2ns     0.00B    0.0%    0.00B\n",
    " initialize matrices        1   15.7μs    0.0%  15.7μs   96.4KiB   98.5%  96.4KiB\n",
    "   init A                   1   7.17μs    0.0%  7.17μs   8.00KiB    8.2%  8.00KiB\n",
    "   init B                   1   3.17μs    0.0%  3.17μs   8.00KiB    8.2%  8.00KiB\n",
    "   init C                   1   2.50μs    0.0%  2.50μs   78.2KiB   79.9%  78.2KiB\n",
    " ────────────────────────────────────────────────────────────────────────────────\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### External: Intel VTune Profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [IntelITT.jl](https://github.com/JuliaPerf/IntelITT.jl) for instrumentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/vtune_gui_flamegraph.png\" width=800px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### External: Tracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See [Tracy.jl](https://github.com/topolarity/Tracy.jl) (for instrumentation) and [this section](https://docs.julialang.org/en/v1/devdocs/external_profilers/#Tracy-Profiler) of the Julia documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/tracy.png\" width=800px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profiling: NVIDIA GPU, MPI, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [NVIDIA Nsight Systems](https://developer.nvidia.com/nsight-systems)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use [**NVTX.jl**](https://github.com/JuliaGPU/NVTX.jl) to instrument and annotate (i.e. label and colorize) code blocks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/report1.png\" width=800px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### More: [Extrae.jl](https://github.com/bsc-quantic/Extrae.jl), [ScoreP.jl](https://github.com/JuliaPerf/ScoreP.jl) ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profiling on hardware-level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we have considered **software** profiling options. Another approach to assessing the performance of a (piece of) Julia code are **hardware** performance counters, which are built into most modern CPUs. These can be accessed with, e.g., [LinuxPerf.jl](https://github.com/JuliaPerf/LinuxPerf.jl) and [LIKWID.jl](https://github.com/JuliaPerf/LIKWID.jl)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LIKWID Example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/likwid_example.png\" width=900px>"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.10.5",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
