{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed Computing: Distributed.jl (standard library)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programming model\n",
    "\n",
    "<img src=\"./imgs/distributedjl_model.svg\" width=850>\n",
    "\n",
    "**Master-worker paradigm**:\n",
    "* One master process coordinates a set of worker processes (that eventually perform computations).\n",
    "* Programmer only controls the master directly. The workers are \"instructed\" (**one-sided** communication).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding and removing workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nworkers() # the master is considered a worker as long as there are no other workers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To increase the number of workers, i.e. Julia processes, we can call **`addprocs`**.\n",
    "\n",
    "(Alternatively, one can set the number of worker processes when starting julia with the `-p` option. E.g. `julia -p 4` gives 5 processes, 1 master and 4 workers.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "addprocs(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every process has a Julia internal `pid` (process id). **The master always has pid 1.** You can get the worker pids from `workers()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One master to rule them all - `@spawn`, `@spawnat`, `@fetch`, `@fetchfrom`, `@everywhere`..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To submit computations to any worker we can use\n",
    "\n",
    "* `@spawn`: run a command or a code block on any worker and return a `Future` (a wrapped `Task`) to it's result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the conceptual similarity between `Threads.@spawn` (task → thread) and `Distributed.@spawn` (task → process)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@spawn 3+3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = @spawn 3+3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`@fetch` does the same, just in one command. It has **blocking** semantics and only returns once the result has arrived."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@fetch 3+3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@fetch rand(3,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which worker did the work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@fetch begin\n",
    "    println(myid());\n",
    "    3+3\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now that we understood all that, let's delegate a *complicated* calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "using Random\n",
    "\n",
    "function complicated_calculation()\n",
    "    sleep(1) # so complex that it takes a long time :)\n",
    "    randexp(5)\n",
    "end\n",
    "\n",
    "@fetch complicated_calculation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happened?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Every worker is a separate Julia process.** (Think of having multiple Julia REPLs open at once.)\n",
    "\n",
    "We only defined `complicated_calculation()` on the master process. The function doesn't exist on any of the workers.\n",
    "\n",
    "The macro `@everywhere` allows us to perform steps on all processes (master and worker). This is particularly useful for loading packages and defining functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere begin # execute this block on all workers\n",
    "    using Random\n",
    "    \n",
    "    function complicated_calculation()\n",
    "        sleep(1)\n",
    "        randexp(5)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@fetch complicated_calculation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data movement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sending messages and moving data typically constitute most of the overhead in a distributed program. **Reducing the number of messages and the amount of data sent is critical to achieving performance and scalability.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is **implicitly** transferred to a worker as part of a task that needs it. Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function method1()\n",
    "    A = rand(100,100)\n",
    "    B = rand(100,100)\n",
    "    C = @fetch A^2 * B^2\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`A` and `B` are created on the master process, transferred to a worker, squared and multiplied by the worker before the result is finally transferred back to the master."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare this to this similar implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function method2()\n",
    "    C = @fetch rand(100,100)^2 * rand(100,100)^2\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the entire computation happens on a worker process. Only the result is transferred to the master."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's benchmark:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using BenchmarkTools\n",
    "@btime method1();\n",
    "@btime method2();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that there are more tools for explicit data movement like `RemoteChannels` and [ParallelDataTransfer.jl](https://github.com/ChrisRackauckas/ParallelDataTransfer.jl/). For the sake of brevity, we will not cover them here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Fortunately, many useful parallel computations do not require (much) data movement at all. A common example is a direct Monte Carlo simulation, where multiple processes can handle independent simulation trials simultaneously. → **montecarlo_pi** exercise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High-level tools: `@distributed` and `pmap`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have seen some of the fundamental building blocks for distributed computing with Distributed.jl. However, in practice, one wants to think as little as possible about how to distribute the work and explicitly spawn tasks in parallel programs.\n",
    "\n",
    "Julia provides **high-level convenience** tools to\n",
    " * distribute `map` $\\quad$ → $\\quad$ [`pmap`](https://docs.julialang.org/en/v1/stdlib/Distributed/#Distributed.pmap)\n",
    " * distribute loops $\\quad$ → $\\quad$ [`@distributed`](https://docs.julialang.org/en/v1/stdlib/Distributed/#Distributed.@distributed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel map: `pmap`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very often, one simply wants to parallize a `map` operation where a function `f` is applied to all elements of a collection. This is a typical instance of **data parallelism**, which covers a vast class of compute-intensive programs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map(x->x^2, 1:10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Such a pattern can be parallelized in Julia via the high-level function `pmap` (\"parallel map\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: Singular values of multiple matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere using LinearAlgebra\n",
    "\n",
    "M = Matrix{Float64}[rand(200,200) for i = 1:10]; # array holding 10 matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map(svdvals, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmap(svdvals, M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that this indeed utilized multiple workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmap(M) do m\n",
    "    println(myid())\n",
    "    svdvals(m)\n",
    "end\n",
    "\n",
    "# do synax:\n",
    "#\n",
    "# pmap(M) do m\n",
    "#     ...\n",
    "# end\n",
    "#\n",
    "# is the same as\n",
    "#\n",
    "# pmap(m -> ..., M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@btime map($svdvals, $M);\n",
    "@btime pmap($svdvals, $M);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributed loops (`@distributed`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: Reduction\n",
    "\n",
    "Reductions (e.g. `sum`) can't be expressed with `pmap` (e.g. $\\mathbb{R}^n \\rightarrow \\mathbb{R}$ vs $\\mathbb{R}^n \\rightarrow \\mathbb{R}^n$).\n",
    "\n",
    "Task: Counting heads in a series of coin tosses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function count_heads_loop(n)\n",
    "    c = 0\n",
    "    for i = 1:n\n",
    "        c += rand((0,1))\n",
    "    end\n",
    "    return c\n",
    "end\n",
    "\n",
    "N = 200_000_000\n",
    "@btime count_heads_loop($N);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Here, `+` is the **reducer function**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can parallelize this reduction using\n",
    "* `@distributed (reducer function) for ...`.\n",
    "\n",
    "Note that this has **blocking** character and returns the result once it has arrived."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function count_heads_distributed_loop(n)\n",
    "    c = @distributed (+) for i in 1:n\n",
    "        rand((0,1))\n",
    "    end\n",
    "    return c\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@btime count_heads_distributed_loop($N);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distributed version is about **4x faster**, which is all we could hope for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`@distributed` distributes the work **evenly** among the workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function count_heads_distributed_verbose(n)\n",
    "    c = @distributed (+) for i in 1:n\n",
    "        x = rand((0,1))\n",
    "        println(x)\n",
    "        x\n",
    "    end\n",
    "    c\n",
    "end\n",
    "\n",
    "count_heads_distributed_verbose(8);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `@distributed` vs `pmap`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Julia's `pmap` is designed for the case where\n",
    "\n",
    "* one wants to apply **a function to a collection**,\n",
    "* one needs **load-balancing** (e.g. workload is non-uniform), and/or\n",
    "* each function call does enough work to amortize the overhead. \n",
    "\n",
    "On the other hand, `@distributed` is good for\n",
    "\n",
    "* **reductions** (can't be written as `map`/`pmap`),\n",
    "* loops where each iteration **takes about the same time** (uniform workload), and/or\n",
    "* loops where the workload of each iteration is (very) small."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating workers on other machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting worker processes (via `addprocs`) is handled by [ClusterManagers](https://docs.julialang.org/en/v1/manual/distributed-computing/#ClusterManagers).\n",
    "\n",
    "* The default is `LocalManager`. It is automatically used when running `addprocs(i::Integer)`.\n",
    "* Another manager is `SSHManager`. It is automatically used when running `addprocs(hostnames::Array)`, e.g. `addprocs([\"node123\", \"node456\"])`. The only requirement is a **passwordless ssh access** to all specified hosts.\n",
    "* Cluster managers for SLURM, PBS, and others are provided in [ClusterManagers.jl](https://github.com/JuliaParallel/ClusterManagers.jl). For SLURM, this will make `addprocs` use `srun` under the hood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Example*\n",
    "\n",
    "```julia\n",
    "using Distributed\n",
    "\n",
    "addprocs([\"node123\", \"node123\"])\n",
    "\n",
    "@everywhere println(gethostname())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can also start multiple processes on different machines:\n",
    "```julia\n",
    "addprocs([(\"node123\", 2), (\"node456\", 3)]) # starts 2 workers on node123 and 3 workers on node456\n",
    "\n",
    "# Use :auto to start as many processes as CPU threads are available\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleanup\n",
    "rmprocs(workers())"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.10.5",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
