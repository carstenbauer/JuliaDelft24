{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42d3d18f",
   "metadata": {},
   "source": [
    "# Compilation\n",
    "\n",
    "To be fast, Julia needs to specialize code, that is **compile specific native versions of the code**. The better the specialization the faster the code!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6add0fc5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## \"Just ahead of time\" compilation\n",
    "\n",
    "* Julia specializes on the **types of function arguments** and \n",
    "* compiles efficient machine code **when a function is called for the first time** (with these input argument types).\n",
    "\n",
    "If the same function is called again with the same input argument types, the already existing machine code is reused.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2352e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "func(x,y) = 2x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa5f7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [1.2, 3.4, 5.6] # Vector{Float64}\n",
    "y = [0.4, 0.7, 0.9] # Vector{Float64}\n",
    "\n",
    "@time func(x,y);\n",
    "@time func(x,y);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a475ea",
   "metadata": {},
   "source": [
    "**First call:** compilation + running the code\n",
    "\n",
    "**Second call:** running the code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44115394",
   "metadata": {},
   "outputs": [],
   "source": [
    "@time func(x,y);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74b788e",
   "metadata": {},
   "source": [
    "If one of the input types changes, Julia compiles a new specialization of the function!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21df8af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "typeof(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4add9224",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [1, 3, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb28c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "typeof(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49854ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@time func(x,y); # Vector{Int64}, Vector{Float64}\n",
    "@time func(x,y);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c9af6e-a348-4871-aa89-53f310098baa",
   "metadata": {},
   "source": [
    "We now have two efficient native codes in the cache: one for all `Vector{Float64}` inputs and another one for `Vector{Int64}` as the first and `Vector{Float64}` as the second argument type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b8c246-cad7-4155-8fc5-899862be6cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "methods(func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8254a81-c2a3-4773-9c4f-7ed7ef160dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "using MethodAnalysis\n",
    "methodinstances(func)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d5e0dc-d5ea-4e8c-b285-df29f3a37105",
   "metadata": {},
   "source": [
    "### Compilation pipeline\n",
    "\n",
    "<p><br><img src=\"imgs/Julia_compilation_pipeline.svg\" width=\"512\"/></p>\n",
    "\n",
    "* **AST**: abstract syntax tree\n",
    "* **IR**: intermediate representation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b6c894-0b8b-4457-aa21-c82389fa7671",
   "metadata": {},
   "source": [
    "## Introspection tools\n",
    "#### (*But I really want to see what happens!*)\n",
    "\n",
    "We can inspect the code at all transformation stages with a bunch of macros:\n",
    "\n",
    "<img src=\"./imgs/julia_introspection_macros.svg\" width=300px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7a2b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@macroexpand @show 3+3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f33406d-9c41-496b-abce-552cdd221c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "f(x, y) = x^3 + y/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5839c3d5-fa28-41f6-a6a8-2d8eb664894e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@code_lowered f(1.0,2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a0d257",
   "metadata": {},
   "outputs": [],
   "source": [
    "@code_typed f(1.0,2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7543e88-4a3a-48a2-92be-9832b8a69d47",
   "metadata": {},
   "source": [
    "From the types of the input arguments, Julia has figured out all the intermediate types. This crucial process is known as **type inference** and its success is the basis for a good specialization (i.e. performant native code as a result). Moreover, the generic power function computing the cubic of `x` is replaced by specific floating-point multiplications (**static dispatch**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a33e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "@code_llvm debuginfo=:none f(1.0,2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d1afc8-f12d-4922-95ea-9e7e15a64040",
   "metadata": {},
   "source": [
    "The expensive divide operation (`y/2`) is replaced by multiplying by 0.5. In the end, giving two `Float64` arguments this function has 4 floating-point operations, i.e. 3 multiplications and 1 addition, instead of cubic function and division."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae32331",
   "metadata": {},
   "outputs": [],
   "source": [
    "@code_native debuginfo=:none f(1.0,2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b6ed56",
   "metadata": {},
   "source": [
    "Let's compare this to integer inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6e9653",
   "metadata": {},
   "outputs": [],
   "source": [
    "@code_native debuginfo=:none f(1,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45872508",
   "metadata": {},
   "source": [
    "## How important is specialization?\n",
    "\n",
    "Let's try to estimate the performance gain by specialization. To prevent specialization, we deliberately throw away any useful type information and operate on a `Vector{Any}` that can literally store anything!\n",
    "\n",
    "(This is qualitatively comparable to what Python does.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307bed1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "func(v) = 2*v[1] + v[2] # version of func that takes in a vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef3134a-027f-41c3-8d7f-11ffe11ca355",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c6ae38-70dd-42a3-a723-8b4eea2bacab",
   "metadata": {},
   "outputs": [],
   "source": [
    "Any[rand(), rand()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7eadf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "using BenchmarkTools\n",
    "\n",
    "v_typed = rand(2)\n",
    "v_any = Any[rand(), rand()]\n",
    "\n",
    "@btime func($v_typed);\n",
    "@btime func($v_any);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1524e3f-22e5-4a64-ab19-dd97350499ee",
   "metadata": {},
   "source": [
    "For benchmarking we generally use `@btime` (or `@benchmark`) from [BenchmarkTools.jl](https://github.com/JuliaCI/BenchmarkTools.jl). This will take care of a couple of things for us:\n",
    "* Exclude first run.\n",
    "* Run the code multiple times (â†’ statistics).\n",
    "* Benchmark in a function (local scope).\n",
    "\n",
    "**General rule:** For good benchmarking use `@btime` and interpolate (`$`) global input arguments.\n",
    "\n",
    "(Prefixing variable with `$` always means interpolation in Julia, e.g. string interpolation.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8283840e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@benchmark func($v_any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaaf2ba3-ac9b-4cdf-a5a0-17e748f1b4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "@code_typed func(rand(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e4ac87-01c7-4a4f-9e78-64a298bbdec7",
   "metadata": {},
   "source": [
    "**static dispatch**: the generic functions `*` and `+` are replaced by specific implementations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70cd881-b2f0-4559-8015-5953c3fea257",
   "metadata": {},
   "outputs": [],
   "source": [
    "@code_typed func(Any[rand(), rand()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21663ee4-0c69-4d76-83de-cea6a56a791f",
   "metadata": {},
   "source": [
    "Note here the generic functions `*` and `+` can not be replaced by specific variants due to lack of type information. This leads to inefficient **runtime dispatch**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc90c012",
   "metadata": {},
   "source": [
    "## Dispatch and specialization\n",
    "\n",
    "**Types drive both dispatch and specialization.**\n",
    "\n",
    "First, the most specific method is selected (dispatch), then it gets compiled to efficient native code (specialization). Let's reconsider our earlier example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274d6488",
   "metadata": {},
   "outputs": [],
   "source": [
    "myabs(x::Real) = sign(x) * x\n",
    "myabs(z::Complex) = sqrt(real(z * conj(z)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9145b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "@code_native myabs(3.2 + 4.5im) # complex input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5fb226",
   "metadata": {},
   "outputs": [],
   "source": [
    "@code_native myabs(3 + 4im) # also complex input but different native code (due to specialization)!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a84601-3036-411d-99a9-b82aebe8e1c6",
   "metadata": {},
   "source": [
    "## Precompilation\n",
    "\n",
    "Besides the \"just ahead of time\" compilation discussed above, **Julia precompiles packages and stores the resulting binary code (among other things).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e321a7-e2b7-45e8-bcd5-8da44f1ccdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "Base.compilecache_dir(Base.PkgId(BenchmarkTools))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5e8bd2-0a17-495b-90f0-b3cb06eb94ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "readdir(Base.compilecache_dir(Base.PkgId(BenchmarkTools)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef64848b-6e37-4cf8-a08d-29df33a930e3",
   "metadata": {},
   "source": [
    "### A note for heterogeneous HPC clusters\n",
    "\n",
    "By default, precompilation produces native code for the CPU type it is running on. This means that it uses the [Instruction Set Architecture (ISA)](https://en.wikipedia.org/wiki/Instruction_set_architecture) of this CPU.\n",
    "\n",
    "This can lead to issues on heterogeneous clusters where different nodes have different CPU types. E.g. you precompile Julia packages on a login node with an Intel CPU but want to run the code on a compute node with AMD CPUs.\n",
    "\n",
    "**Solution: Multiversioning**\n",
    "\n",
    "```julia\n",
    "# HLRS Training Cluster\n",
    "export JULIA_CPU_TARGET=\"generic;sandybridge,clone_all;cascadelake,clone_all;skylake-avx512,clone_all\"\n",
    "```\n",
    "\n",
    "This will compile a generic (but slow) version as well as efficient variants for Intel Sandybridge and Intel Cascade Lake and Intel Skylake CPUs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271288b7",
   "metadata": {},
   "source": [
    "# Core messages of this Notebook\n",
    "\n",
    "* **A function is compiled when called for the first time** with a given set of argument types.\n",
    "* There are **multiple code transformation steps** which can be inspected through macros like `@code_warntype` or `@descend` from Cthulhu.jl.\n",
    "* What makes Julia fast? Successful **Type inference** â†’ **Specialization** â†’ **Compilation**.\n",
    "* Functions should almost always be benchmarked with **BenchmarkTools.jl's `@btime` and `@benchmark`** instead of `@time`.\n",
    "* In virtually all cases, **explicit type annotations are irrelevant for performance**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.5",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
