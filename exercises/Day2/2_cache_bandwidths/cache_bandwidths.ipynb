{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56086671-dbeb-4027-b195-f615854e0096",
   "metadata": {},
   "source": [
    "# Exercise: Cache Bandwidths\n",
    "\n",
    "In this exercise you will benchmark a **Schoenauer triad** kernel (i.e. `y[i] = a[i] * x[i] + y[i]`) and see how the observed performance is effected by the memory hierarchy, i.e. different cache levels.\n",
    "\n",
    "**Hint:** On most systems, you can programmatically query the cache sizes via\n",
    "\n",
    "```julia\n",
    "using CpuId\n",
    "cachesize()\n",
    "```\n",
    "\n",
    "(It doesn't work on Apple silicon.)\n",
    "\n",
    "## Tasks\n",
    "\n",
    "1) Inspect the code below and implement the missing piece (look for the single TODO annotation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298599ca-6da9-4528-a229-88e47e089727",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "using Plots\n",
    "using BenchmarkTools\n",
    "using CpuId\n",
    "using Statistics\n",
    "\n",
    "\"\"\"\n",
    "SDAXPY: `y[i] = a[i] * x[i] + y[i]` (Schoenauer triad without write-allocate.)\n",
    "\n",
    "The arguments `y, a, x` are vectors of length `n`.\n",
    "\"\"\"\n",
    "function sdaxpy!(y, a, x, n)\n",
    "    #\n",
    "    # TODO: Implement the SDAXPY kernel. Use `@inbounds` to turn-off bound checks.\n",
    "    #\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    vector_lengths(lo::Integer, hi::Integer, ni::Integer; factor::Integer=32)\n",
    "\n",
    "Given some lower (`lo`) and upper (`hi`) bound in bytes, returns â‰¤ ni distinct integers\n",
    "that are\n",
    "- more or less evenly separated between lo and hi\n",
    "- multiples of `factor`\n",
    "\n",
    "These integers are to be used as vector lengths for the inputs to `sdaxpy!` and determine\n",
    "the number of loop iterations therein.\n",
    "\"\"\"\n",
    "function vector_lengths(lo::Integer, hi::Integer, ni::Integer; factor::Integer=32)\n",
    "    r_log = range(log10(lo / 32), log10(hi / 32), ni)\n",
    "    r = round.(Integer, exp10.(r_log))\n",
    "    r_factor = r .& (~(factor-1)) # biggest multiple of factor <= number\n",
    "    return unique(r_factor)\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Perform a benchmark of the SDAXPY kernel (Schoenauer triad without write-allocate).\n",
    "See `vector_lengths` for explanations of the input arguments.\n",
    "\"\"\"\n",
    "function bench(lo, hi, n; nbench, kwargs...)\n",
    "    ts = Float64[]\n",
    "    Ns = vector_lengths(lo, hi, n; kwargs...)\n",
    "    for n in Ns\n",
    "        y = fill(1.2, n)\n",
    "        a = fill(0.8, n)\n",
    "        x = fill(3.14, n)\n",
    "        t = @belapsed for i in 1:$nbench\n",
    "            sdaxpy!($y, $a, $x, $n)\n",
    "        end samples = 30\n",
    "        push!(ts, t / nbench)\n",
    "        println(\"finished n = $n, time: \", ts[end], \" sec bandwidth: \", 32.0e-9 * n / ts[end], \" GB/s\")\n",
    "        flush(stdout)\n",
    "    end\n",
    "    return Ns, ts\n",
    "end\n",
    "\n",
    "function plot_results(Ns, ts)\n",
    "    p = plot(Ns, Ns ./ ts .* 32.0e-9, marker=:circle, label=\"sdaxpy!\", frame=:box, ms=2, xscale=:log10)\n",
    "    ylabel!(p, \"bandwidth [GB/s]\")\n",
    "    xlabel!(p, \"vector size n\")\n",
    "    L1, L2, L3 = cachesize()\n",
    "    mem = 4 * sizeof(Float64) # four arrays a, b, c, and d in `sdaxpy!`\n",
    "    nL1 = L1 / mem\n",
    "    nL2 = L2 / mem\n",
    "    nL3 = L3 / mem\n",
    "    vline!(p, [nL1], color=:orange, lw=2, label=\"L1 = $(floor(Int, nL1)) ($(L1/1024) KiB)\")\n",
    "    vline!(p, [nL2], color=:red, lw=2, label=\"L2 = $(floor(Int, nL2)) ($(L2/1024) KiB)\")\n",
    "    vline!(p, [nL3], color=:purple, lw=2, label=\"L3 = $(floor(Int, nL3)) ($(L3/1024) KiB)\")\n",
    "    return p\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Will perform the benchmark and save a plot of the results as png/svg files.\n",
    "\"\"\"\n",
    "function main()\n",
    "    L1, L2, L3 = cachesize()\n",
    "    Ns1, ts1 = bench(1024, L1, 12; nbench=2^24, factor=32)\n",
    "    Ns2, ts2 = bench(round(Integer, L1 * 1.5), L2, 10; nbench=2^14, factor=64)\n",
    "    Ns3, ts3 = bench(round(Integer, L2 * 1.5), L3, 10; nbench=2^10, factor=128)\n",
    "    Ns4, ts4 = bench(round(Integer, L3 * 1.5), L3 * 32, 8; nbench=2^4, factor=64)\n",
    "    p = plot_results(vcat(Ns1, Ns2, Ns3, Ns4), vcat(ts1, ts2, ts3, ts4))\n",
    "    # savefig(p, \"sdaxpy_contiguous.svg\")\n",
    "    println(\"L1 bandwidth:\\t\", round(median(32.0e-9 .* Ns1 ./ ts1); digits=2), \" GB/s\")\n",
    "    println(\"L2 bandwidth:\\t\", round(median(32.0e-9 .* Ns2 ./ ts2); digits=2), \" GB/s\")\n",
    "    println(\"L3 bandwidth:\\t\", round(median(32.0e-9 .* Ns3 ./ ts3); digits=2), \" GB/s\")\n",
    "    println(\"Memory bandwidth:\\t\", round(median(32.0e-9 .* Ns4 ./ ts4); digits=2), \" GB/s\")\n",
    "    return p\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bdf25d1-41bc-4987-bb1e-c5ee7dbdc1da",
   "metadata": {
    "tags": []
   },
   "source": [
    "2) Run the benchmark by calling the `main()` function. (Note that this can take up to ~7 minutes.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062db65d-5d4f-4eda-a5b7-259a1eba0e8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@time main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f292ecd0-b3cc-45ab-ad28-e780cf5a8f60",
   "metadata": {
    "tags": []
   },
   "source": [
    "* **Questions**\n",
    "  * Do you understand the trend of the resulting plot?\n",
    "  * Which bandwidth estimates (in GB/s) do you obtain for L1, L2, L3, and main memory? (Check the textual output of the benchmark.) Fill out the table below.\n",
    "  \n",
    "|  measurements   |  bandwidth [GB/s] |\n",
    "|:---------------:|:-----------------:|\n",
    "|  L1D cache      |  TODO              |\n",
    "|  L2  cache      |  TODO              |\n",
    "|  L3  cache      |  TODO              |\n",
    "|  main memory    |  TODO               |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7393e100-ed73-4a14-b2dc-65a3f2cd685c",
   "metadata": {},
   "source": [
    "Let's now investigate the performance impact of **strided data access** in comparison to the contiguous data access (as benchmarked above).\n",
    "\n",
    "3) Copy the entire code from above in the cell below and modify the `sdaxpy!` function such that it only performs the SDAXPY computation to every other vector element (i.e. instead of `1:n` you iterate over `1:2:n`). This corresponds to a stride size of 2.\n",
    "\n",
    "4) Since we now only perform half as many operations and thus only half of the data transfer, we need to account for this change in all bandwidth computations. Specifically, check all lines that contain `32.0e-09` and insert an extra factor of 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3ac5f8-5c74-49f4-b413-a755204fa67b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5848ea-27ae-4931-b2cf-440edc42d2ee",
   "metadata": {},
   "source": [
    "5) Run the benchmark for the strided SDAXPY. How do the results compare to the contiguous case? What's the reason?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e85d2bd-e62e-43b5-8e5a-eb63cd7196d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@time main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia (1 thread) 1.10.0",
   "language": "julia",
   "name": "julia-_1-thread_-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
